{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning intro\n",
    "\n",
    "![](https://newapplift-production.s3.amazonaws.com/comfy/cms/files/files/000/001/201/original/machine-learning-robots-dilbert.gif) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "Training and quality assessment of the model is carried out on independent sets of examples. As a rule, existing examples are divided into two subsets: training (train) and test (test). The choice of split ratio is a compromise. Indeed, the large size of the training leads to better algorithms, but more noise when evaluating the model on the test. Conversely, a large test sample size leads to a less noisy quality assessment, but the trained models are less accurate.\n",
    "\n",
    "Many classification models predict a rating of membership to a positive class $ \\tilde {y} (x) \\in R $ (for example, the probability of being a class 1). After that, a decision is made on the class of the object by comparing the estimate with a certain threshold $ \\ theta $:\n",
    "\n",
    "$$y(x) = \n",
    "\\begin{cases}\n",
    "+1, &\\text{if} \\; \\tilde{y}(x) \\geq \\theta \\\\\n",
    "-1, &\\text{if} \\; \\tilde{y}(x) < \\theta\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In this case, we can consider metrics that can work with the initial response of the classifier. In the assignment, we will work with the AUC-ROC metric, which in this case can be considered as the proportion of incorrectly ordered pairs of objects sorted by ascending the predicted grade 1 grade. A detailed understanding of how the AUC-ROC metrics work for this lab is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of hyperparameters of the model\n",
    "\n",
    "In machine learning tasks, one should distinguish between model parameters and hyperparameters (structural parameters). Typically, model parameters are adjusted during training (for example, weights in a linear model or a decision tree structure), while hyper parameters are set in advance (for example, the value of the regularization force in a linear model or the maximum depth of a decision tree). Each model, as a rule, has a lot of hyperparameters and there are no universal sets of hyperparameters that work optimally in all tasks, so for each task you need to choose your own set.\n",
    "\n",
    "To optimize the hyperparameters, models often use _bind on the grid (grid search) _: for each hyperparameter, several values are selected, then all combinations of values are selected and a combination is selected on which the model shows the best quality (in terms of the metric being optimized). However, in this case, it is necessary to correctly evaluate the constructed model, namely, to do the partition into a training and test sample. There are several schemes for how this can be implemented:\n",
    "\n",
    " - Break the available sample into training and test. In this case, the comparison of a large number of models in the enumeration of hyperparameters leads to a situation where the best model on the test subsample does not retain its qualities on the new data. We can say that there is a _transition_ on a test sample.\n",
    " - To eliminate the problem described above, you can split the data into 3 non-overlapping subsamples: training, validation, and test. Validation subsample is used to compare models, and test - for the final quality assessment and comparison of families of models with selected hyperparameters.\n",
    " - Another way to compare models is [cross-validation] (http://bit.ly/1CHXsNH). There are various cross-validation schemes:\n",
    "  - Leave-One-Out\n",
    "  - K-Fold\n",
    "  - Repeated random sampling\n",
    "  \n",
    "Cross validation is computationally expensive, especially if you are iterating over a grid with a very large number of combinations. Given the finiteness of the time to perform the task, a number of compromises arise: \n",
    "  - the hyperparameter grid can be made more sparse by going through fewer values of each hyperparameter; however, you should not forget that in this case you can skip a good combination of hyperparameters;\n",
    "  - cross-validation can be done with a smaller number of splits or folds, but in this case the quality assessment becomes more noisy and the risk of choosing a non-optimal set of hyperparameters increases due to randomness of splitting\n",
    "  - hyperparameters can be optimized sequentially (greedily) - one by one, and not to go through all the combinations; such a strategy does not always lead to an optimal set;\n",
    "  - sort through not all combinations of hyperparameters, but a small number of randomly selected ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn to teach machine learning models, correctly set up experiments, select hyperparameters, compare and mix models. You are invited to solve the problem of binary classification, namely, to build an algorithm that determines whether the average person’s earnings exceed the threshold$50k.\n",
    " \n",
    "More details about the features can be read [here] (http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). The target attribute is written in the variable *> 50K, <= 50K *.\n",
    "\n",
    "Download the data set * data.adult.csv *. To better understand what you are working with / whether you have correctly loaded the data, you can display the first few lines on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>&gt;50K,&lt;=50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>284843</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>190290</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>177858</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>184756</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>149700</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   34  Local-gov  284843       HS-grad              9       Never-married   \n",
       "1   40    Private  190290  Some-college             10            Divorced   \n",
       "2   36  Local-gov  177858     Bachelors             13  Married-civ-spouse   \n",
       "3   22    Private  184756  Some-college             10       Never-married   \n",
       "4   47    Private  149700     Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "        occupation   relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Farming-fishing  Not-in-family  Black    Male           594             0   \n",
       "1            Sales  Not-in-family  White    Male             0             0   \n",
       "2   Prof-specialty      Own-child  White    Male             0             0   \n",
       "3            Sales      Own-child  White  Female             0             0   \n",
       "4     Tech-support        Husband  White    Male         15024             0   \n",
       "\n",
       "   hours-per-week >50K,<=50K  \n",
       "0              60      <=50K  \n",
       "1              40      <=50K  \n",
       "2              40      <=50K  \n",
       "3              30      <=50K  \n",
       "4              40       >50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data.adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there are gaps in the data. The way to designate gaps is either prescribed in the data description, or at the skip place after reading the data, the value [NaN] appears (https://docs.scipy.org/doc/numpy-1.13.0/user/misc.html). For more information about working with passes in Pandas, you can read for example [here] (http://pandas.pydata.org/pandas-docs/stable/missing_data.html).\n",
    "In this dataset, missing values are marked with a \"?\".\n",
    "\n",
    "** (1 point) Task 1. ** Usually, after loading a dataset, some preprocessing is always necessary. In this case, it will be as follows:\n",
    " - Find all the features that have missing values. Remove from the sample all objects with gaps.\n",
    " - Save the target variable (the one we want to predict) into a separate variable, remove it from the dataset and convert to a binary format.\n",
    " - Please note that not all features are real (numeric). In the beginning we will work only with real features. Save them separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Training classifiers on real features\n",
    "\n",
    "In this section, it will be necessary to work only with real attributes and the target variable.\n",
    "\n",
    "In the beginning we will look at how the selection of hyperparameters on the grid works and how the quality of the partitioning affects the quality. Now and further we will consider 4 algorithms:\n",
    " - [kNN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    " - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    " - [SGD Linear Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    " - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "To begin with, the first three algorithms will choose one hyperparameter, which we will optimize:\n",
    "  - kNN - number of neighbors (* n_neighbors *)\n",
    "  - DecisonTree - tree depth (* max_depth *)\n",
    "  - SGD Linear Classifier - optimized function (* loss *)\n",
    " \n",
    "Leave the default values for the remaining hyperparameters. For the selection of hyperparameters, use the search on the grid, which is implemented in the class [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). As a cross-validation scheme, use 5-Fold CV, which can be set using the class [KFoldCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold).\n",
    "\n",
    "![](https://i.stack.imgur.com/YWgro.gif)\n",
    "\n",
    "\n",
    "\n",
    "**(1.5 points) Task 2.** For each algorithm, select the optimal values of the specified hyperparameters. Build a graph of the average value of the quality of the cross-validation algorithm for a given value of the hyperparameter, which also display the confidence interval.\n",
    "\n",
    "To obtain the value of quality on each fold, the average value of quality and other useful information, you can use the field [*cv results_*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "\n",
    "Which algorithm has the highest average quality ?\n",
    "\n",
    "Largest confidence interval ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 point) Task 3.** Now let's select the number of trees (* n_estimators *) in the RandomForest algorithm. As you know, in general, Random Forest does not retrain with an increase in the number of trees. Pick the number of trees starting from which the quality on cross-validation stabilizes. Note that to conduct this experiment, it is not necessary to train many random forests with different numbers of trees from scratch: train one random forest with the maximum interesting number of trees, and then consider subsets of trees of different sizes consisting of trees of the constructed forest (field [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). In further experiments, use the number of trees found.\n",
    "\n",
    "It is difficult to apply the * GridSearchCV * class in this task, so it is suggested to write a cycle on the number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When learning algorithms, it is worth paying attention not only to their quality, but also how they work with data. In this problem, it turned out that some of the algorithms used are sensitive to the scale of features. To make sure that this could affect the quality, let's look at the meanings of the attributes themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point) Task 4.** Look at the values of the signs * age *, * fnlwgt *, * capital-gain *. What is the feature of the data? Which of the considered algorithms can affect this? Can scaling affect the operation of these algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can scale attributes, for example, in one of the following ways:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, where $\\mu, \\sigma$ — the mean and standard deviation of the characteristic value over the entire sample (see the function [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, where $[x_{min}, x_{max}]$ — minimum interval of characteristic values\n",
    "\n",
    "Similar scaling schemes are given in classes [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) and [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
    " \n",
    "**(1 point) Task 5.** \n",
    "\n",
    "Scale all numerical attributes using one of the above methods and select the optimal values of the hyperparameters in the same way as above.\n",
    "\n",
    "Has the quality of some algorithms changed and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 point) Task 6.** Now go through several hyperparameters across the grid and find the optimal combinations (best average quality value) for each algorithm in this case:\n",
    "  - KNN - number of neighbors (* n_neighbors *) and metric (* metric *)\n",
    "  - DecisonTree - tree depth (* max_depth *) and partitioning criterion (* criterion *)\n",
    "  - RandomForest - the partitioning criterion in trees (* criterion *) and the maximum number of considered features (* max_features *); use the trees found earlier\n",
    "  - SGDClassifier - optimized function (* loss *) and * penalty *\n",
    " \n",
    "Please note that this operation can be resource intensive and time consuming. How to optimize the selection of parameters on the grid is described in the section \"Selection of hyperparameters of the model\".\n",
    "\n",
    "Which algorithm has the best quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points) Task 7.** Build for different algorithms graphics [learning curves](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html), depicting the dependence of quality on test and training samples on the number of objects on which models are trained. Look at the behavior of the curves and answer the questions:\n",
    "* Can the quality on the test sample decrease with an increase in the number of objects? And on the training? Why? \n",
    "* For what purposes can quality knowledge be used on the training part of the sample?\n",
    "* Which algorithm is better trained on fewer objects?\n",
    "* Can the addition of new objects significantly improve the quality of any of the algorithms or, with the existing data set for all algorithms, saturation occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point) Adding categorical features to models\n",
    "\n",
    "So far we have not used non-numeric attributes that are in dataset. Let's see if we did the right thing and whether the quality of the models will increase after adding these attributes.\n",
    "\n",
    "**(0.5 points) Task 8.** Transform all categorical features using the one-hot-encoding method (for example, you can do this using [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) or [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) / [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) from sklearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since after coding, signs turned out to be quite a lot, in this work we will not re-select the optimal hyperparameters for models taking into account new signs (although it would be better to do it). \n",
    "\n",
    "**(0.5 points) Task 9.** Add coded categorical to scaled real-time features and train algorithms with the best hyper-parameters found earlier. Did the addition of new signs increase the quality? Measure quality as before using a 5-fold CV. For this it is convenient to use the function [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score).\n",
    "\n",
    "Is the best classifier now different from the best in the previous paragraph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Mixing models (blending)When implementing their models, it is good practice to create sklearn-compatible classes. First, such an implementation will have a standard interface and will allow other people to teach the models you have implemented without serious consequences. Secondly, it is possible to use any sklearn package functionality that accepts a model as input, for example, the class * GridSearchCV *, * learning_curve * and others.\n",
    "\n",
    "Create a classifier that is initialized with two arbitrary classifiers and the $ \\ alpha $ parameter. During training, such a classifier should train both basic models, and at the stage of prediction, knead predictions of basic models according to the formula indicated above.\n",
    "\n",
    "To create a custom classifier, you must inherit from the base classes.\n",
    "\n",
    "\n",
    "In all the preceding paragraphs, we obtained many strong models that can be quite different in nature (for example, the method of the nearest neighbors and the random forest). Often in practice it is possible to increase the quality of prediction by mixing different models. Let's see if this approach really gives an increase in quality.\n",
    "\n",
    "Choose from the constructed models of the two previous points two, which gave the highest quality on cross-validation (we denote them $ clf_1 $ and $ clf_2 $). Next, build a new classifier, whose answer on some object $ x $ will look like this:\n",
    "\n",
    "$$result(x) = clf_1(x) * \\alpha + clf_2(x) * (1 - \\alpha)$$\n",
    "\n",
    "where $ \\alpha $ is a hyper-parameter of the new classifier.\n",
    "\n",
    "**(1 point) Task 10.**\n",
    "When implementing their models, it is good practice to create sklearn-compatible classes. First, such an implementation will have a standard interface and will allow other people to teach the models you have implemented without serious consequences. Secondly, it is possible to use any sklearn package functionality that accepts a model as input, for example, the class * GridSearchCV *, * learning_curve * and others.\n",
    "\n",
    "Create a classifier that is initialized with two arbitrary classifiers and the $ \\ alpha $ parameter. During training, such a classifier should train both basic models, and at the stage of prediction, knead predictions of basic models according to the formula indicated above.\n",
    "\n",
    "To create a custom classifier, you must inherit from the base classes.\n",
    "*[BaseEstimator](http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html), [ClassifierMixin](http://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html)* and implement methods*\\_\\_init\\_\\_, fit, predict and predict_proba*. Example sklearn-compatible classifier with comments can be found [here](http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point) Task 11.** Select the value $ \\ alpha $ for this classifier from the grid from 0 to 1. If the class is implemented correctly, then you can use * GridSearchCV *, as is the case with conventional classifiers.\n",
    "\n",
    "Draw on the graph the average quality of the folds and the confidence interval depending on $ \\ alpha $.\n",
    "\n",
    "Did this approach increase in quality compared to models that were trained separately? Explain why even simple blending of models can influence the final quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1 point) Models comparison\n",
    "\n",
    "![](http://cdn.shopify.com/s/files/1/0870/1066/files/compare_e8b89647-3cb6-4871-a976-2e36e5987773.png?1750043340268621065)\n",
    "\n",
    "After many models have been built, the right continuation is to compare them with each other. At the visualization workshop, you were shown how to build a “mustache box” (span diagram). We use it to compare the algorithms with each other.\n",
    "\n",
    "**(1 point) Task 12.** For each type of classifier (kNN, DecisionTree, RandomForest, SGD classifier), as well as a mixed model, choose the one that gave the best quality for cross-validation and build a span diagram. All classifiers should be displayed on the same graph.\n",
    " \n",
    "Make general summary conclusions about the classifiers in terms of their work with the signs and the complexity of the model itself (what kind of hyperparameters the model has, whether changing the value of the hyperparameter greatly affects the quality of the model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
