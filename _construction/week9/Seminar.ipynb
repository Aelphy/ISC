{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymPy Intro\n",
    "\n",
    "Take a look [here](https://safwanahmad.github.io/2018/01/21/Linear-Regression-A-Tale-of-a-Transform.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras\n",
    "and why do they matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warming up\n",
    "* Implement a function that computes the sum of squares of numbers from 0 to N\n",
    "* Use numpy or python\n",
    "* An array of numbers 0 to N - numpy.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_squares(N):\n",
    "    return (np.arange(N)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 414 ms, sys: 429 ms, total: 842 ms\n",
      "Wall time: 840 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "662921401752298880"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sum_squares(10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow teaser\n",
    "\n",
    "Doing the very same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/72/6b3264aa2889b7dde7663464b99587d95cd6a5f3b9b30181f14d78a63e64/tensorflow-2.0.0-cp37-cp37m-macosx_10_11_x86_64.whl (102.7MB)\n",
      "\u001b[K     |████████████████████████████████| 102.7MB 9.4MB/s eta 0:00:01    |█████████████████████████████   | 93.1MB 6.9MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.16.4)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/22/c462571c795d7071847f1046fbdb43c03ec1b358948c2c83ff56691e5a32/grpcio-1.24.3-cp37-cp37m-macosx_10_9_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c6/a8b6a74ab1e165f0aaa673a46f5c895af8780976880c98934ae82060356d/protobuf-3.10.0-cp37-cp37m-macosx_10_9_intel.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 9.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 14.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: h5py in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 6.4MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/81/d1e7d9974ba7c886f6d133a8baae18cb8d92b2d09bcc4f46328306825de0/google_auth-1.7.0-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 3.4MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<3.2,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 7.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aelphy/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.6.16)\n",
      "Building wheels for collected packages: absl-py, opt-einsum, termcolor, gast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/aelphy/Library/Caches/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/aelphy/Library/Caches/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/aelphy/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/aelphy/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built absl-py opt-einsum termcolor gast\n",
      "Installing collected packages: keras-preprocessing, absl-py, keras-applications, opt-einsum, termcolor, grpcio, protobuf, tensorflow-estimator, gast, astor, google-pasta, oauthlib, requests-oauthlib, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-auth-oauthlib, markdown, tensorboard, tensorflow\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 gast-0.2.2 google-auth-1.7.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.24.3 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.10.0 pyasn1-0.4.7 pyasn1-modules-0.2.7 requests-oauthlib-1.2.0 rsa-4.0 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I gonna be function parameter\n",
    "N = tf.placeholder(tf.int64)\n",
    "\n",
    "#i am a recipe on how to produce sum of squares of arange of N given N\n",
    "result = tf.reduce_sum(tf.range(N)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "session.run(result, feed_dict={N : 10**8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does it work?\n",
    "__if you're currently in classroom, chances are i am explaining this text wall right now__\n",
    "* 1 You define inputs for your future function;\n",
    "* 2 You write a recipe for some transformation of inputs;\n",
    "* 3 You ask session to compute it with the values you provide session with;\n",
    "* You have just got a graph!\n",
    "\n",
    "* There are two main kinds of entities: \"Inputs\" and \"Transformations\"\n",
    "* Both can be numbers, vectors, matrices, tensors, etc.\n",
    "* Both can be integers, floats of booleans (uint8) of various size.\n",
    "\n",
    "\n",
    "* An input is a placeholder for function parameters.\n",
    " * N from example above\n",
    "\n",
    "\n",
    "* Transformations are the recipes for computing something given inputs and transformation\n",
    " * tf.reduce_sum(tf.range(N)^2) are 3 sequential transformations of N\n",
    " \n",
    "Still confused? We gonna fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 # a rank 0 tensor; this is a scalar with shape []\n",
    "[1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inputs\n",
    "example_input_integer = tf.Variable(1)\n",
    "\n",
    "example_input_tensor = tf.Variable(np.ones((100, 3, 50, 50)))\n",
    "#do not warry, we won't need tensor\n",
    "#yet\n",
    "\n",
    "input_vector = tf.Variable(np.ones(5, dtype=np.float32)) # vector of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transformations\n",
    "\n",
    "#transofrmation: elementwise multiplication\n",
    "double_the_vector = input_vector * 2\n",
    "\n",
    "#elementwise cosine\n",
    "elementwise_cosine = tf.cos(input_vector)\n",
    "\n",
    "#difference between squared vector and vector itself\n",
    "vector_squares = input_vector**2 - input_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practice time:\n",
    "#create two vectors of size float32\n",
    "my_vector = student.init_float32_vector()\n",
    "my_vector2 = student.init_one_more_such_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write a transformation(recipe):\n",
    "#(vec1)*(vec2) / (sin(vec1) +1)\n",
    "my_transformation = student.implementwhatwaswrittenabove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(my_transformation)\n",
    "#it's okay it aint a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling\n",
    "* So far we were using \"symbolic\" variables and transformations\n",
    " * Defining the recipe for computation, but not computing anything\n",
    "* To use the recipe, one should compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The next lines defines a function that takes two vectors and computes your transformation\n",
    "def my_function(val1, val2):\n",
    "    a = <the first vector that my_transformation depends on>\n",
    "    b = <the second vector that my_transformation depends on>\n",
    "    outputs = [<What do we compute (can be a list of several transformation)>]\n",
    "    \n",
    "    return session.run(outputs, {a : val1, b : val2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using function with, lists:\n",
    "print('using python lists:')\n",
    "print(my_function([1, 2, 3], [4, 5, 6]))\n",
    "print()\n",
    "\n",
    "#Or using numpy arrays:\n",
    "#btw, that 'float' dtype is casted to secong parameter dtype which is float32\n",
    "print('using numpy arrays:')\n",
    "print(my_function(np.arange(10),\n",
    "                  np.linspace(5, 6, 10, dtype='float')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When debugging, one would generally want to reduce the computation complexity. For example, if you are about to feed neural network with 1000 samples batch, consider taking first 2.\n",
    "* If you really want to debug graph of high computation complexity, you could just as well compile it (e.g. with optimizer='fast_compile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quest #1 - implement a function that computes a mean squared error of two input vectors\n",
    "# Your function has to take 2 vectors and return a single number\n",
    "\n",
    "<student.define_inputs_and_transformations()>\n",
    "\n",
    "def compute_mse(<student.define_function_arguments()>):\n",
    "    <student.compile_function()>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for n in [1, 5, 10, 10**3]:\n",
    "    elems = [np.arange(n), np.arange(n, 0, -1), np.zeros(n),\n",
    "             np.ones(n), np.random.random(n), np.random.randint(100, size=n)]\n",
    "    \n",
    "    for el in elems:\n",
    "        for el_2 in elems:\n",
    "            true_mse = np.array(mean_squared_error(el, el_2))\n",
    "            my_mse = compute_mse(el, el_2)\n",
    "            \n",
    "            if not np.allclose(true_mse, my_mse):\n",
    "                print('Wrong result:')\n",
    "                print('mse({},{})'.format(el, el_2))\n",
    "                print('should be: {}, but your function returned {}'.format(true_mse, my_mse))\n",
    "                raise ValueError, 'Smth went wrong'\n",
    "\n",
    "print('All tests passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could already see two types of graph inputs:\n",
    "* placeholders\n",
    "* Variables\n",
    "\n",
    "There also exist constants:\n",
    "\n",
    "`tf.constant(5)` - constant is initialized during its creation, what is opposite to Variables and placeholders.\n",
    "One could see Variables as global variables that allows to put the data to graph and read the values from outside of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(np.ones([200, 150, 5, 3]), expected_shape=[None, 150, 5, 3])\n",
    "\n",
    "try:\n",
    "    session.run(a)\n",
    "except:\n",
    "    print(\"A variable was not initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to initialize Variable you have to call\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a recipe (transformation) that computes an elementwise transformation of shared_vector and input_scalar\n",
    "#Compile as a function of input_scalar\n",
    "\n",
    "input_constant = tf.constant(5.0) # dtype is infered (or could be set implicitly with dtype = option)\n",
    "\n",
    "constant_times_variable = <student.write_recipe()>\n",
    "\n",
    "variable_times_n = <student.make_a_function()>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shared_times_n(5)', variable_times_n(5))\n",
    "\n",
    "print('shared_times_n(-0.5)', variable_times_n(-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing value of vector 1 (output should change)\n",
    "shared_vector_1.assign(5 * shared_vector_1)\n",
    "\n",
    "print('shared_times_n(5)', variable_times_n(5))\n",
    "\n",
    "print('shared_times_n(-0.5)', variable_times_n(-0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T.grad - why tensorflow matters\n",
    "* tensorflow can compute derivatives and gradients automatically\n",
    "* Derivatives are computed symbolically, not numerically\n",
    "\n",
    "Limitations:\n",
    "* You can only compute a gradient of a __scalar__ transformation over one or several scalar or vector (or tensor) transformations or inputs.\n",
    "* A transformation has to have float32 or float64 dtype throughout the whole computation graph\n",
    " * derivative over an integer has no mathematical sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_scalar = tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "scalar_squared = tf.reduce_sum(my_scalar**2)\n",
    "\n",
    "#a derivative of v_squared by my_vector\n",
    "derivative = tf.gradients(scalar_squared, my_scalar)\n",
    "\n",
    "fun = lambda x: session.run(scalar_squared, {my_scalar: x})\n",
    "grad = lambda x: session.run(derivative, {my_scalar: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(-3, 3)\n",
    "x_squared = list(map(fun, x))\n",
    "x_squared_der = list(map(grad, x))\n",
    "\n",
    "plt.plot(x, x_squared, label='x^2')\n",
    "plt.plot(x, x_squared_der, label='derivative')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why that rocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_vector = tf.placeholder(tf.float64)\n",
    "\n",
    "#Compute the gradient of the next weird function over my_scalar and my_vector\n",
    "#warning! Trying to understand the meaning of that function may result in permanent brain damage\n",
    "\n",
    "weird_psychotic_function = tf.reduce_mean((my_vector+my_scalar)**(1+tf.nn.moments(my_vector, axes=[0])[1]) + 1. / tf.log(my_scalar + tf.sqrt(my_scalar**2 + 1))) / (my_scalar**2 + 1) + 0.01 * tf.sin(2 * my_scalar**1.5) * (tf.reduce_sum(my_vector) * my_scalar**2) * tf.exp((my_scalar - 4)**2) / (1 + tf.exp((my_scalar - 4)**2)) * (1. - (tf.exp( - (my_scalar - 4)**2)) / (1 + tf.exp( - (my_scalar - 4)**2)))**2\n",
    "\n",
    "der_by_scalar, der_by_vector = #<student.compute_grad_over_scalar_and_vector()>\n",
    "\n",
    "compute_weird_function = lambda x, y: session.run(weird_psychotic_function, {my_scalar : x, my_vector : y })\n",
    "compute_der_by_scalar = lambda x, y: session.run(der_by_scalar, {my_scalar : x, my_vector : y })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting your derivative\n",
    "vector_0 = [1, 2, 3]\n",
    "\n",
    "scalar_space = np.linspace(0, 7)\n",
    "\n",
    "y = [compute_weird_function(x, vector_0) for x in scalar_space]\n",
    "plt.plot(scalar_space, y, label='function')\n",
    "y_der_by_scalar = [compute_der_by_scalar(x, vector_0) for x in scalar_space]\n",
    "plt.plot(scalar_space, y_der_by_scalar, label='derivative')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression example\n",
    "\n",
    "Implement the regular logistic regression training algorithm\n",
    "\n",
    "Tips:\n",
    "* Weights fit in as a shared variable\n",
    "* X and y are potential inputs\n",
    "* Compile 2 functions:\n",
    " * train_function(X, y) - returns error and computes weights' new values __(through updates)__\n",
    " * predict_fun(X) - just computes probabilities (\"y\") given data\n",
    " \n",
    " \n",
    "We shall train on a two-class MNIST dataset\n",
    "* please note that target y are {0,1} and not {-1,1} as in some formulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits(2)\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "print('y [shape - {}]:{}'.format(str(y.shape), y[:10]))\n",
    "print('X [shape - {}]:'.format(str(X.shape))\n",
    "print(X[:3])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs and shareds\n",
    "shared_weights = <student.code_me()>\n",
    "input_X = <student.code_me()>\n",
    "input_y = <student.code_me()>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = <predicted probabilities for input_X>\n",
    "loss = <logistic loss (scalar, mean over sample)>\n",
    "\n",
    "grad = <gradient of loss over model weights>\n",
    "\n",
    "updates = {\n",
    "    shared_weights: <new weights after gradient step> #Implement your favorite stochastic optimization algorithm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_function = <compile function that takes X and y, returns log loss and updates weights>\n",
    "predict_function = <compile function that takes X and computes probabilities of y>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in range(5):\n",
    "    loss_i = train_function(X_train,y_train)\n",
    "    print('loss at iter {}:{}'.format(i, loss_i)\n",
    "    print('train auc:', roc_auc_score(y_train,predict_function(X_train)))\n",
    "    print('test auc:', roc_auc_score(y_test,predict_function(X_test)))\n",
    "    \n",
    "print('resulting weights:')\n",
    "          \n",
    "plt.imshow(shared_weights.get_value().reshape(8, -1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "f = x / x\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print(session.run(f, {x : 0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus task:\n",
    "\n",
    "implement regression assignment with SymPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "I did such and such, that did that cool thing and my awesome logistic regression bloated out that stuff. Finally, i did that thing and felt like Einstein. That cool article and that kind of weed helped me so much (if any)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "314px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "371px",
    "left": "0.989583px",
    "right": "20px",
    "top": "106.997px",
    "width": "249px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
