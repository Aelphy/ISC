{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (PageRank) \n",
    "\n",
    "## 3 pts\n",
    "\n",
    "### Connected graph\n",
    "\n",
    "* First of all create PageRank matrix $A$ that corresponds to the following graph: <img src=\"graph1.png\" width='200'> Make sure that your matrix is stochastic. What is the largest eigenvalue of this matrix?\n",
    "\n",
    "\n",
    "* Implement power method and plot relative errors ${|\\lambda_{k+1} - 1|}$ and $\\frac{\\|x_{k+1} - x_{k}\\|}{\\|x_{k+1}\\|}$ (since you have no information about $x$) as a function of $k$, where $k$ is the interation number. <font color='red'>DO NOT FORGET TO USE LOGARITHMIC SCALE!</font>\n",
    "\n",
    "### Disconneted graph: damping factor importance\n",
    "\n",
    "* Create PageRank matrix $A$ that corresponds to the following graph: <img src=\"graph2.png\" width='200'>\n",
    "\n",
    "* Run the power method and plot relative errors ${|\\lambda_{k+1} - 1|}$  and $\\frac{\\|x_{k+1} - x_{k}\\|}{\\|x_{k+1}\\|}$ as a function of $k$. Why do you observe the absense of convergence? <br> **Hint:** think about the multiplicity of $\\lambda=1$\n",
    "\n",
    "In order to avoid this problem Larry Page and Sergey Brin proposed to use the following regularization technique:\n",
    "$$\n",
    "A_d = dA + \\frac{1-d}{N} \\begin{pmatrix} 1 & \\dots & 1 \\\\ \\vdots & & \\vdots \\\\ 1 & \\dots & 1 \\end{pmatrix},\n",
    "$$\n",
    "where $d$ is small parameter (typically $d=0.85$), which is called **damping factor**, $A$ is of size $N\\times N$. Now $A_d$ is the matrix with multiplicity of the largest eigenvalue equal to 1. \n",
    "Recall that computing the eigenvector of the PageRank matrix which corresponds to the largest eigenvalue has the following interpretation: consider a person who stays in a random node of the graph (i.e. opens a random web page); at each step he follows one of the outcoming edges uniformly at random (i.e. opens one of the links). So the guy randomly walks through the graph and the eigenvector we are looking for is exactly his stationary distribution â€” for each node it tells you the probability of visiting this particular node. Therefore if the guy has started from a part of a graph which is not connected with the other part, he will never get there.  In the regularized model the person at each step follows one of the outcoming links with probability $d$ OR visits a random node from the whole graph with probability $(1-d)$.\n",
    "\n",
    "* Now run the power method with $A_d$ and plot errors as a function of iteration for different $d$.\n",
    "\n",
    "### Simple English Wiki\n",
    "\n",
    "Let us now find the most significant articles on the simple english Wikipedia according to the PageRank model. We provide you with the adjecency matrix of the simple Wikipedia articles (file `simple_wiki_matrix.mat`, matrix can be acessed by the key `'W'`) and the dictionary that maps article id to its name on Wikipedia (file `simple_wiki_dict.pickle`).\n",
    "\n",
    "* Normalize each column of the adjecency matrix to get a matrix from the PageRank model. Check that the obtained matrix is stochastic.\n",
    "\n",
    "* Plot relative errors ${|\\lambda_{k+1} - 1|}$  and $\\frac{\\|x_{k+1} - x_{k}\\|}{\\|x_{k+1}\\|}$ as a function of $k$ for different $d$. **Note** that your matrix contains a lot of zeros and is stored in the sparse format. Hence `np.dot(A, x)` will not work. However, sparse matrices has method `.dot()`, so `A.dot(x)` works fine.\n",
    "\n",
    "* Print names of top-5 articles when $d=0.85$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 column sums grater than 1\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "W = sp.io.loadmat('simple_wiki_matrix.mat')['W']\n",
    "    \n",
    "W_normalized = normalize(W.astype(np.double), norm='l2', axis=0).astype(np.int32)\n",
    "column_sums = np.array(W_normalized.sum(0))[0]\n",
    "\n",
    "print('There are {0} column sums grater than 1'.format(len([col_sum for col_sum in column_sums if col_sum > 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (Eigenfaces)\n",
    "\n",
    "## 3 pts\n",
    "\n",
    "<img src='http://de-bug.de/medien/files/uploads/2009/01/image-eigenfaces.png' width=250>\n",
    "\n",
    "The aim of this task is to build a face classifier. There are 40 persons in the database. Every person is represented by 10 photos with slightly different facial expression. \n",
    "- The database of faces is attached: `orl_faces.zip`\n",
    "\n",
    "- Create training sample:\n",
    "\n",
    "  Import first 9 images for each face ($9\\times 40$ images). Represent these pictures as a matrix $F$ with $9\\times 40$ columns, where each column is a reshaped 2D picture. Note: use `np.reshape` to reshape matrix into column\n",
    "  \n",
    "  \n",
    "- Calculate and plot mean face. Subtract it from each column of the matrix $F$\n",
    "\n",
    "- Calculate SVD decomposition of the shifted matrix F and truncate the obtained representaition: $F_r = U_r S_r V_r^T$. \n",
    "\n",
    " Here $U_r$ is a matrix with $r$ columns - basis set in a space of faces. $W_r = S_r V_r^T$ is a matrix of coefficients in the basis $U_r$. Note that now every image is represented as a small number of coefficients in the basis $U_r$.\n",
    " \n",
    " \n",
    "- Plot vectors in $U_r$ using subplots. Make sure that you get face-like images. Now you know what eigenfaces are =)\n",
    "\n",
    "- Import testing set which is the rest of photos. Find their coefficients in the basis $U_r$. \n",
    "\n",
    "- Compare the obtained vectors of coefficients to vectors in $W_r$ using cosine similarity and classify testing faces. As an output give indices of faces that were misclassified when $r=5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. 3 pts\n",
    "<img src=\"https://www.researchgate.net/profile/Kimon_Fountoulakis/publication/315527144/figure/fig4/AS:657817354657796@1533847287350/Left-Visualization-of-Facebook-Ego-Graph-where-color-represents-community-membership.png\" width='800'>\n",
    "\n",
    "* Implement a BFS and DFS functions (do not use ready implementations).\n",
    "<img src=\"http://mishadoff.com/images/dfs/binary_tree_search.png\" width='800'>\n",
    "* Make both of them [generators](https://wiki.python.org/moin/Generators) and be happy that now you will actually work with loops despite you already proved in the past that they are evil.\n",
    "\n",
    "* Test your implementations on [ego-Facebook](https://snap.stanford.edu/data) graph. Compare run times and memory consumption (I want to see good plots here: with titles, subscribed axes, etc.).\n",
    "\n",
    "__BONUS AREA__\n",
    "* Implement Dijkstra algorithm.\n",
    "Use it to find the longest shortest path in the same graph (the longest distance between two connected users).\n",
    "\n",
    "* Implement Prim and Kruskal algorithms (do not use ready implementations). Test them on the graph. Compare run times and memory consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4. 1 pt\n",
    "\n",
    "Implement a class for Heap data structure (do not use ready implementations).\n",
    "Implement `heap_sort` function which takes array as input and returns sorted version of the array.\n",
    "Compare speed of you algorithm with built-in Python `sorted()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
